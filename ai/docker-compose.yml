version: '3.8'
services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    volumes:
      - ./ai_data/code:/code
      - ./ai_data/ollama/ollama:/root/.ollama
    container_name: ollama
    pull_policy: always
    tty: true
    restart: always
    # networks:
    #   - ollama-docker
    # 在這裡加入 Fluentd Logging Driver
    # logging:
    #   driver: "fluentd"
    #   options:
    #     # fluentd-address: localhost:24224
    #     fluentd-address: localhost:24224
    #     tag: ollama
    # # 為了可以透過 Server localhost 使用 Fluentd 的 Port
    # extra_hosts:
    #   - "localhost:host-gateway"

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    volumes:
      - ./ai_data/ollama/open-webui:/app/backend/data
    depends_on:
      - ollama
    ports:
      - 8099:8080
    environment:
      - '/ollama/api=http://ollama:11434/api'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    # networks:
    #   - ollama-docker

# networks:
#   ollama-docker:
# #     external: false
# networks:
#   default:
#     external:
#       name: custom-fluentd_default
#       # external: true
#       # name: wrenai_wren